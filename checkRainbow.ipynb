{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "from g2p_en import G2p\n",
    "import re\n",
    "\n",
    "from basicOperations.manifoldOperations import matrixDistance, frechetMean\n",
    "\n",
    "from rnn import euclideanRnnNato\n",
    "import math\n",
    "\n",
    "import pickle\n",
    "from Levenshtein import distance\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Proof for Figure 5 and Table 7.\n",
    "Use the trained checkpoints from natorWordsEuclidean.ipynb to test it here on rainbow passage. \n",
    "Reported value in the article is the average from here and checkGrandfather.ipynb.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = \"cuda:0\" \n",
    "device = torch.device(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Phonemize nato alphabets.\"\"\"\n",
    "\n",
    "natoAlphabets = [\n",
    "    \"Alfa\", \"Bravo\", \"Charlie\", \"Delta\", \"Echo\", \n",
    "    \"Foxtrot\", \"Golf\", \"Hotel\", \"India\", \"Juliette\",\n",
    "    \"Kilo\", \"Lima\", \"Mike\", \"November\", \"Oscar\", \n",
    "    \"Papa\", \"Quebec\", \"Romeo\", \"Sierra\", \"Tango\",\n",
    "    \"Uniform\", \"Victor\", \"Whiskey\", \"X-ray\", \"Yankee\",\n",
    "    \"Zulu\"]\n",
    "\n",
    "englishAlphabets = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\"]\n",
    "\n",
    "PHONE_DEF = ['AA', 'AE', 'AH', 'AO', 'AY', 'B', 'CH', 'D', 'EH', 'ER', 'EY', 'F', 'G', 'HH', 'IH',\n",
    " 'IY', 'JH', 'K', 'L', 'M', 'N', 'NG', 'OW', 'P', 'R', 'S', 'T', 'UW', 'V', 'W', 'Y', 'Z', 'SIL']\n",
    "\n",
    "alphabetNumber = {\"A\": 0, \"B\": 1, \"C\": 2, \"D\": 3, \"E\": 4, \"F\": 5, \"G\": 6, \"H\": 7, \"I\": 8, \"J\": 9, \"K\": 10, \"L\": 11, \"M\": 12, \"N\": 13, \"O\": 14, \"P\": 15, \"Q\": 16, \"R\": 17, \"S\": 18, \"T\": 19, \"U\": 20, \"V\": 21, \"W\": 22, \"X\": 23, \"Y\": 24, \"Z\": 25}\n",
    "numberAlphabet = {0: \"A\", 1: \"B\", 2: \"C\", 3: \"D\", 4: \"E\", 5: \"F\", 6: \"G\", 7: \"H\", 8: \"I\", 9: \"J\", 10: \"K\", 11: \"L\", 12: \"M\", 13: \"N\", 14: \"O\", 15: \"P\", 16: \"Q\", 17: \"R\", 18: \"S\", 19: \"T\", 20: \"U\", 21: \"V\", 22: \"W\", 23: \"X\", 24: \"Y\", 25: \"Z\"}\n",
    "\n",
    "def phoneToId(p):\n",
    "    return PHONE_DEF.index(p)\n",
    "\n",
    "g2p = G2p()\n",
    "\n",
    "phonemizedAlphabets = []\n",
    "for i in range(len(natoAlphabets)):\n",
    "    alphabet = natoAlphabets[i].strip()\n",
    "    alphabet = re.sub(r'[^a-zA-Z\\- \\']', '', alphabet)\n",
    "    alphabet = alphabet.replace('--', '').lower()\n",
    "    phones = []\n",
    "    for p in g2p(alphabet):\n",
    "        p = re.sub(r'[0-9]', '', p)   \n",
    "        if re.match(r'[A-Z]+', p):   \n",
    "            phones.append(p)\n",
    "    phonemizedAlphabets.append(phones)\n",
    "\n",
    "phone2index = []\n",
    "for i in range(len(phonemizedAlphabets)):\n",
    "    current = phonemizedAlphabets[i]\n",
    "    phoneID = []\n",
    "    for j in range(len(current)):\n",
    "        phoneID.append(phoneToId(current[j]))\n",
    "    phone2index.append(phoneID)\n",
    "\n",
    "phonemizedLabels = np.zeros((26, 8))\n",
    "for i in range(26):\n",
    "    phonemizedLabels[i, 0:len(phone2index[i])] = phone2index[i]\n",
    "\n",
    "labelLengths = np.zeros((26))\n",
    "for i in range(len(phone2index)):\n",
    "    labelLengths[i] = len(phone2index[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testOperation(model, device, testLoader, Loss):\n",
    "    model.eval()\n",
    "    totalLoss = 0\n",
    "    Outputs = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets, inputLengths, targetLengths in testLoader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            inputLengths, targetLengths = inputLengths.to(device), targetLengths.to(device)\n",
    "            \n",
    "            outputs = model(inputs, inputLengths.cpu()) \n",
    "\n",
    "            loss = Loss(outputs, targets, inputLengths, targetLengths)\n",
    "            totalLoss += loss.item()\n",
    "            Outputs.append(outputs.transpose(0, 1))\n",
    "\n",
    "    return Outputs, totalLoss / len(testLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberAlphabets = 26\n",
    "trialsPerAlphabet = 20\n",
    "numberTrials = numberAlphabets * trialsPerAlphabet\n",
    "numberChannels = 22\n",
    "windowLength = 7500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Upload data. \"\"\"\n",
    "\n",
    "subjectNumber = 4\n",
    "subject = \"Subject\" + str(subjectNumber)\n",
    "\n",
    "DATA = np.load(\"DATA/\" + subject + \"/rainbowPassage.npy\")\n",
    "\n",
    "mean = np.mean(DATA, axis = -1)\n",
    "std = np.std(DATA, axis = -1)\n",
    "DATA = (DATA - mean[..., np.newaxis])/(std[..., np.newaxis] + 1e-5)\n",
    "\n",
    "Labels = np.load(\"DATA/\" + subject + \"/rainbowPassageLabels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of articulation in the rainbow passage:  1427\n"
     ]
    }
   ],
   "source": [
    "print(\" Number of articulation in the rainbow passage: \", len(Labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1427, 46, 22, 22)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Chunk the data. Load eigenvectors. Approximately diagonalize it.\"\"\"\n",
    "\n",
    "slicedMatrices = np.zeros((len(Labels), 46, numberChannels, numberChannels))\n",
    "for j in range(len(Labels)):\n",
    "    for i in range(46):\n",
    "        where = i * 150 + 300\n",
    "        start = where - 300\n",
    "        End = where + 450\n",
    "        temp = 1/750 * DATA[j, :, start:End] @ DATA[j, :, start:End].T\n",
    "        slicedMatrices[j, i] = 0.9 * temp + 0.1 * np.trace(temp) * np.eye(numberChannels)\n",
    "\n",
    "\n",
    "eigenvectors = np.load(\"DATA/ckptsNatoWords/eigenVectors\" + str(subjectNumber) + \".npy\")\n",
    "\n",
    "\n",
    "afterMatrices = np.zeros((len(Labels), 46, numberChannels, numberChannels))\n",
    "for i in range(len(Labels)):\n",
    "    for j in range(46):\n",
    "        temp = eigenvectors.T @ slicedMatrices[i, j] @ eigenvectors\n",
    "        afterMatrices[i, j] = temp\n",
    "print(afterMatrices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseDataset(Dataset):\n",
    "    def __init__(self, data, labels, targetLength):\n",
    "        self.data = data \n",
    "        self.labels = labels\n",
    "        self.targetLength = targetLength\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        inputSeq = self.data[index].astype('float32')  \n",
    "        targetSeq = self.labels[index]\n",
    "        inputLength = int(self.data.shape[1])\n",
    "        targetLength = int(self.targetLength[index])\n",
    "        return inputSeq, targetSeq, inputLength, targetLength\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "testFeatures = np.zeros((len(Labels), 46, numberChannels, numberChannels))\n",
    "testLabels = np.zeros((len(Labels), 8))\n",
    "testLabelLengths = np.zeros((len(Labels)))\n",
    "for i in range(len(Labels)):\n",
    "    testFeatures[i] = afterMatrices[i]\n",
    "    testLabels[i] = phonemizedLabels[Labels[i]]\n",
    "    testLabelLengths[i] = labelLengths[Labels[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataset = BaseDataset(testFeatures, testLabels, testLabelLengths)\n",
    "testDataloader = DataLoader(testDataset, batch_size = 32, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"A simple beamsearch algorithm.\"\"\"\n",
    "\n",
    "def beamSearch(ctcOutput, testInputLength, beamWidth = 5, blank = 32):\n",
    "    _, V = ctcOutput.shape\n",
    "    T = int(testInputLength)\n",
    "    beams = [(tuple(), 0.0)] \n",
    "    \n",
    "    for t in range(T):\n",
    "        newBeams = {}\n",
    "        for seq, logProb in beams:\n",
    "            for symbol in range(V):\n",
    "                newSeq = list(seq)\n",
    "                \n",
    "                if symbol == blank:\n",
    "                    newLogProb = logProb + ctcOutput[t, symbol].item()\n",
    "                    newSeq = tuple(newSeq)\n",
    "                \n",
    "                elif len(seq) == 0 or seq[-1] != symbol:\n",
    "                    newSeq.append(symbol)\n",
    "                    newLogProb = logProb + ctcOutput[t, symbol].item()\n",
    "                    newSeq = tuple(newSeq)\n",
    "                \n",
    "                else:\n",
    "                    newLogProb = logProb + ctcOutput[t, symbol].item()\n",
    "                    newSeq = tuple(newSeq)\n",
    "                \n",
    "                if newSeq in newBeams:\n",
    "                    newBeams[newSeq] = math.log(math.exp(newBeams[newSeq]) + math.exp(newLogProb))\n",
    "                else:\n",
    "                    newBeams[newSeq] = newLogProb\n",
    "\n",
    "        beams = sorted(newBeams.items(), key=lambda x: x[1], reverse=True)[:beamWidth]\n",
    "    \n",
    "    return beams[0][0]\n",
    "\n",
    "def findBestMatch(prediction, alphabetSequences):\n",
    "    \n",
    "    minDistance = float('inf')\n",
    "    closestKeys = []\n",
    "\n",
    "    for key, phoneticTranscription in alphabetSequences.items():\n",
    "        dist = distance(prediction, phoneticTranscription)\n",
    "        \n",
    "        if dist < minDistance:\n",
    "            minDistance = dist\n",
    "            closestKeys = [key]\n",
    "        elif dist == minDistance:\n",
    "            minDistance = dist\n",
    "            closestKeys.append(key)\n",
    "        \n",
    "\n",
    "    return closestKeys, minDistance\n",
    "\n",
    "alphabetSequences = {}\n",
    "for i in range(26):\n",
    "    alphabetSequences[englishAlphabets[i]] = phone2index[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280121\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda:0\"\n",
    "\n",
    "numberEpochs = 100\n",
    "\n",
    "model = euclideanRnnNato.RnnNet(33, 23, device, numLayers = 1).to(device)\n",
    "numParams = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(numParams)\n",
    "lossFunction = nn.CTCLoss(blank = 32, zero_infinity = True)\n",
    "rnnOptimizer = optim.Adam(model.parameters(), lr = 0.001, weight_decay = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66\n"
     ]
    }
   ],
   "source": [
    "\"\"\"FOLDERPATH = \"ckpts/natoEuclidean/\"\n",
    "valLoss = np.load(FOLDERPATH + \"valLoss.npy\")\n",
    "chosenEpoch = None\n",
    "sortedIndices = np.argsort(valLoss)\n",
    "\n",
    "for idx in sortedIndices:\n",
    "    if idx > 0 and idx < len(valLoss) - 1: \n",
    "        currentLoss = valLoss[idx]\n",
    "        threshold = currentLoss * 1.2\n",
    "\n",
    "        if valLoss[idx - 1] <= threshold and valLoss[idx + 1] <= threshold:\n",
    "            chosenEpoch = idx\n",
    "            break\n",
    "\n",
    "valEpoch = chosenEpoch \n",
    "print(valEpoch)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9231127050187853\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(\"DATA/ckptsNatoWords/subject\" + str(subjectNumber) + \"Euclidean.pt\", weights_only = True)\n",
    "model.load_state_dict(checkpoint)\n",
    "output, valLoss = testOperation(model, device, testDataloader, lossFunction)\n",
    "output = torch.concatenate(output)\n",
    "print(valLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PER:  0.5812924166420773\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Calculate PER.\"\"\"\n",
    "\n",
    "lev = []\n",
    "labelLength = []\n",
    "for i in range(len(Labels)):\n",
    "    decodedSymbols = beamSearch(output[i].cpu().numpy(), 46)\n",
    "    lev.append(distance(decodedSymbols, alphabetSequences[numberAlphabet[Labels[i]]]))\n",
    "    labelLength.append(len(alphabetSequences[numberAlphabet[Labels[i]]]))\n",
    "\n",
    "print(\"PER: \", np.mean(lev)/np.mean(labelLength))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CER:  0.4386825508058865\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Calculate CER.\"\"\"\n",
    "\n",
    "corrects = 0\n",
    "for i in range(len(Labels)):\n",
    "    decodedSymbols = beamSearch(output[i].cpu().numpy(), 46)\n",
    "    bestLetters  = findBestMatch(decodedSymbols, alphabetSequences)\n",
    "    if len(bestLetters[0]) == 1:\n",
    "        if numberAlphabet[Labels[i]] in bestLetters[0]:\n",
    "            corrects += 1\n",
    "\n",
    "print(\"CER: \", corrects/len(Labels))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emgSpeech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
