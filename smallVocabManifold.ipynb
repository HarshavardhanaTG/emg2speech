{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "from g2p_en import G2p\n",
    "import re\n",
    "\n",
    "from basicOperations.manifoldOperations import matrixDistance, frechetMean\n",
    "import torch.nn.utils as utils\n",
    "\n",
    "from rnn import manifoldRnn\n",
    "import math\n",
    "\n",
    "import pickle\n",
    "from Levenshtein import distance\n",
    "import os\n",
    "\n",
    "import Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Proof for table 2, figure 4.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Train SMALL-VOCAB EMG-to-phoneme conversion.\n",
    "\n",
    "This is a small corpora of data containing of 500 sentences.\n",
    "\n",
    "Each sentence is of the following format. WEEKDAY - MONTH - DATE - YEAR.\n",
    "Unlike the data LARGE-VOCAB, we have time-stamps between weekday, month, date, and year (this is a much simpler dataset). \n",
    "\n",
    "A sentence was displayed on GUI and cue was given when to articulate each of the WEEKDAY - MONTH - DATE - YEAR. \n",
    "\n",
    "WEEKDAY - articulated in a window of duration 2s.\n",
    "MONTH - articulated in a window of duration 2s.\n",
    "DATE - articulated in a window of duration 2s.\n",
    "YEAR - articulated in a window of duration 3s.\n",
    "\n",
    "Split each sentence at these boundaries and train the model.\n",
    "\n",
    "This small data can be used for fine-grained analysis such as to developing algoriths to demarcate speech and non-speech using EMG. \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = np.load(\"DATA/dataSmallVocab.npy\")\n",
    "LABELS = np.load(\"DATA/labelsSmallVocab.npy\")[:499]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" z-normalize the data. \"\"\"\n",
    "\n",
    "Mean = np.mean(DATA, axis = -1)\n",
    "Std = np.std(DATA, axis = -1)\n",
    "DATA = (DATA - Mean[..., np.newaxis])/Std[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Convert words to thier phoneme sequences.\"\"\"\n",
    "\n",
    "WORDS = []\n",
    "for i in range(len(LABELS)):\n",
    "    words = LABELS[i]\n",
    "    words = [word.replace(\"-\", \" \").strip().lower() for word in words]\n",
    "    WORDS.append(words)\n",
    "\n",
    "allWORDS = []\n",
    "for i in range(len(WORDS)):\n",
    "    for j in range(len(WORDS[i])):\n",
    "        allWORDS.append(WORDS[i][j])\n",
    "\n",
    "PHONE_DEF = ['AO', 'CH', 'IY', 'AA', 'W', 'S', 'IH', 'K', 'EY', 'JH', 'Y', 'N', 'OW', 'M', 'P', 'T', 'B', 'AY', 'UW', 'R', 'G', 'EH', 'Z', 'TH', 'AW', 'HH', 'AH', 'AE', 'L', 'ER', 'F', 'V', 'D', 'SIL']\n",
    "\n",
    "def phoneToId(p):\n",
    "    return PHONE_DEF.index(p)\n",
    "\n",
    "g2p = G2p()\n",
    "\n",
    "phonemizedWords = []\n",
    "for i in range(len(allWORDS)):\n",
    "    word = re.sub(r'[^a-zA-Z\\- \\']', '', allWORDS[i])\n",
    "    phones = []\n",
    "    for p in g2p(word):\n",
    "        p = re.sub(r'[0-9]', '', p)   \n",
    "        if re.match(r'[A-Z]+', p):   \n",
    "            phones.append(p)\n",
    "    phonemizedWords.append(phones)\n",
    "\n",
    "phone2index = []\n",
    "for i in range(len(phonemizedWords)):\n",
    "    current = phonemizedWords[i]\n",
    "    phoneID = []\n",
    "    for j in range(len(current)):\n",
    "        phoneID.append(phoneToId(current[j]))\n",
    "    phone2index.append(phoneID)\n",
    "\n",
    "phonemizedLabels = np.zeros((499 * 4, 18))\n",
    "for i in range(499 * 4):\n",
    "    phonemizedLabels[i, 0:len(phone2index[i])] = phone2index[i]\n",
    "\n",
    "labelLengths = np.zeros((499 * 4))\n",
    "for i in range(len(phone2index)):\n",
    "    labelLengths[i] = len(phone2index[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Chunk sentences at word boundaries.\"\"\"\n",
    "\n",
    "dataChunk = []\n",
    "for i in range(len(DATA)):\n",
    "    seg1 = DATA[i, :, :10000]\n",
    "    seg2 = DATA[i, :, 10000:20000]\n",
    "    seg3 = DATA[i, :, 20000:30000]\n",
    "    seg4 = DATA[i, :, 30000:]\n",
    "\n",
    "    dataChunk.append(seg1)\n",
    "    dataChunk.append(seg2)\n",
    "    dataChunk.append(seg3)\n",
    "    dataChunk.append(seg4)\n",
    "\n",
    "\n",
    "slicedMatrices = []\n",
    "for j in range(499 * 4):\n",
    "    collect = []\n",
    "\n",
    "    if dataChunk[j].shape[1] == 10000:\n",
    "       \n",
    "        for i in range(38):\n",
    "            where = i * 250 + 250\n",
    "            start = where - 250\n",
    "            End = where + 250\n",
    "            temp = 1/250 * (dataChunk[j][:, start:End] @ dataChunk[j][:, start:End].T)\n",
    "            collect.append(0.9 * temp + 0.1 * np.trace(temp) * np.eye(31))\n",
    "        slicedMatrices.append(collect)\n",
    "\n",
    "    elif dataChunk[j].shape[1] == 15000:\n",
    "        \n",
    "        for i in range(58):\n",
    "            where = i * 250 + 250\n",
    "            start = where - 250\n",
    "            End = where + 250\n",
    "            temp = 1/250 * (dataChunk[j][:, start:End] @ dataChunk[j][:, start:End].T)\n",
    "            collect.append(0.9 * temp + 0.1 * np.trace(temp) * np.eye(31))\n",
    "        slicedMatrices.append(collect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Approximately diagonalize the covariances matrices using Frechet mean. Use only TRAIN-VAL set for ciomputing Frechet mean.\"\"\"\n",
    "\n",
    "matricesForMean = []\n",
    "for i in range(1600):\n",
    "    for j in range(len(slicedMatrices[i])):\n",
    "        matricesForMean.append(slicedMatrices[i][j])\n",
    "\n",
    "matricesForMean = np.array(matricesForMean)\n",
    "manifoldMean = frechetMean()\n",
    "\n",
    "MEAN = manifoldMean.mean(matricesForMean.reshape(-1, 31, 31))\n",
    "eigenvalues, eigenvectors = np.linalg.eig(MEAN)\n",
    "\n",
    "identityMatrix = np.eye(31)\n",
    "afterMatrices = np.tile(identityMatrix, (499 * 4, 58, 1, 1)) \n",
    "inputLengths = np.zeros((499 * 4))\n",
    "for i in range(499 * 4):\n",
    "    for j in range(len(slicedMatrices[i])):\n",
    "        temp = eigenvectors.T @ slicedMatrices[i][j] @ eigenvectors\n",
    "        afterMatrices[i, j] = temp\n",
    "    inputLengths[i] = len(slicedMatrices[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseDataset(Dataset):\n",
    "    def __init__(self, data, labels, inputLength, targetLength):\n",
    "        self.data = data \n",
    "        self.labels = labels\n",
    "        self.targetLength = targetLength\n",
    "        self.inputLength = inputLength\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        inputSeq = self.data[index].astype('float32')  \n",
    "        targetSeq = self.labels[index]\n",
    "        inputLength = int(self.inputLength[index])\n",
    "        targetLength = int(self.targetLength[index])\n",
    "        return inputSeq, targetSeq, inputLength, targetLength\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"TRAIN-VAL-TEST split.\"\"\"\n",
    "\n",
    "trainFeatures = np.zeros((370 * 4, 58, 31, 31))\n",
    "trainLabels = np.zeros((370 * 4, 18))\n",
    "trainLabelLengths = np.zeros((370 * 4))\n",
    "trainInputLengths = np.zeros((370 * 4))\n",
    "\n",
    "valFeatures = np.zeros((30 * 4, 58, 31, 31))\n",
    "valLabels = np.zeros((30 * 4, 18))\n",
    "valLabelLengths = np.zeros((30 * 4))\n",
    "valInputLengths = np.zeros((30 * 4))\n",
    "\n",
    "testFeatures = np.zeros((99 * 4, 58, 31, 31))\n",
    "testLabels = np.zeros((99 * 4, 18))\n",
    "testLabelLengths = np.zeros((99 * 4))\n",
    "testInputLengths = np.zeros((99 * 4))\n",
    "\n",
    "\n",
    "\n",
    "trainFeatures = afterMatrices[:1480]\n",
    "trainLabels = phonemizedLabels[:1480]\n",
    "trainLabelLengths = labelLengths[:1480]\n",
    "trainInputLengths = inputLengths[:1480]\n",
    "\n",
    "valFeatures = afterMatrices[1480:1600]\n",
    "valLabels = phonemizedLabels[1480:1600]\n",
    "valLabelLengths = labelLengths[1480:1600]\n",
    "valInputLengths = inputLengths[1480:1600]\n",
    "\n",
    "testFeatures = afterMatrices[1600:]\n",
    "testLabels = phonemizedLabels[1600:]\n",
    "testLabelLengths = labelLengths[1600:]\n",
    "testInputLengths = inputLengths[1600:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataset = BaseDataset(trainFeatures, trainLabels, trainInputLengths, trainLabelLengths)\n",
    "valDataset = BaseDataset(valFeatures, valLabels, valInputLengths, valLabelLengths)\n",
    "testDataset = BaseDataset(testFeatures, testLabels, testInputLengths, testLabelLengths)\n",
    "\n",
    "\n",
    "trainDataloader = DataLoader(trainDataset, batch_size = 32, shuffle = True)\n",
    "valDataloader = DataLoader(valDataset, batch_size = 32, shuffle = False)\n",
    "testDataloader = DataLoader(testDataset, batch_size = 32, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainOperation(model,  device, trainLoader, rnnOptimizer, Loss):\n",
    "    model.train()\n",
    "    totalLoss = 0\n",
    "    for inputs, targets, inputLengths, targetLengths in trainLoader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        inputLengths, targetLengths = inputLengths.to(device), targetLengths.to(device)\n",
    "        \n",
    "        rnnOptimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = Loss(outputs, targets, inputLengths, targetLengths)\n",
    "        loss.backward()\n",
    "        rnnOptimizer.step()\n",
    "\n",
    "        totalLoss += loss.item()\n",
    "        \n",
    "    \n",
    "    return totalLoss / len(trainLoader)\n",
    "\n",
    "\n",
    "def valOperation(model, device, valLoader, Loss):\n",
    "    model.eval()\n",
    "    totalLoss = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets, inputLengths, targetLengths in valLoader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            inputLengths, targetLengths = inputLengths.to(device), targetLengths.to(device)\n",
    "            \n",
    "            outputs = model(inputs) \n",
    "            loss = Loss(outputs, targets, inputLengths, targetLengths)\n",
    "            totalLoss += loss.item()\n",
    "\n",
    "    return totalLoss / len(valLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5145634\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Set ODE = TRUE or FALSE. For different sizes, change the size of the hidden.\n",
    "\n",
    "If you are loading ckptSmallVoacbManifoldNoODE.pt, set hidden dimesnion to 32.\n",
    "If you are loading ckptSmallVocabManifoldODE.pt, set hidden dimension to 15.\n",
    "\"\"\"\n",
    "\n",
    "dev = \"cuda:0\"\n",
    "device = torch.device(dev)\n",
    "\n",
    "numberEpochs = 100\n",
    "\n",
    "model = manifoldRnn.spdRnnNet(34, hidden = 32, ODE = False, device = device).to(device)\n",
    "numParams = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(numParams)\n",
    "lossFunction = nn.CTCLoss(blank = 33, zero_infinity = True)\n",
    "rnnOptimizer = optim.Adam(model.parameters(), lr = 0.001, weight_decay = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Train the model.\"\"\"\n",
    "valLOSS = []\n",
    "minLOSS = 100\n",
    "for epoch in range(numberEpochs):\n",
    "    trainLoss = trainOperation(model, device, trainDataloader, rnnOptimizer, lossFunction)\n",
    "    valLoss = valOperation(model, device, valDataloader, lossFunction)\n",
    "    valLOSS.append(valLoss)\n",
    "    if minLOSS > valLoss:\n",
    "        minLOSS = valLoss\n",
    "    torch.save(model.state_dict(), \"ckpts/smallVocabManifold/\" + str(epoch) + \".pt\")\n",
    "    print(f'Epoch: {epoch + 1}/{numberEpochs}, Training loss: {trainLoss:.4f}, Val loss: {valLoss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"np.save(\"ckpts/smallVocabManifold/valLoss.npy\", valLOSS)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Simple beam-search algorithm.\n",
    "\"\"\"\n",
    "\n",
    "def beamSearch(ctcOutput, testInputLength, beamWidth = 5, blank = 33):\n",
    "    _, V = ctcOutput.shape\n",
    "    T = int(testInputLength)\n",
    "    beams = [(tuple(), 0.0)] \n",
    "    \n",
    "    for t in range(T):\n",
    "        newBeams = {}\n",
    "        for seq, logProb in beams:\n",
    "            for symbol in range(V):\n",
    "                newSeq = list(seq)\n",
    "                \n",
    "                if symbol == blank:\n",
    "                    newLogProb = logProb + ctcOutput[t, symbol].item()\n",
    "                    newSeq = tuple(newSeq)\n",
    "                \n",
    "                elif len(seq) == 0 or seq[-1] != symbol:\n",
    "                    newSeq.append(symbol)\n",
    "                    newLogProb = logProb + ctcOutput[t, symbol].item()\n",
    "                    newSeq = tuple(newSeq)\n",
    "                \n",
    "                else:\n",
    "                    newLogProb = logProb + ctcOutput[t, symbol].item()\n",
    "                    newSeq = tuple(newSeq)\n",
    "                \n",
    "                if newSeq in newBeams:\n",
    "                    newBeams[newSeq] = math.log(math.exp(newBeams[newSeq]) + math.exp(newLogProb))\n",
    "                else:\n",
    "                    newBeams[newSeq] = newLogProb\n",
    "\n",
    "        beams = sorted(newBeams.items(), key = lambda x: x[1], reverse = True)[:beamWidth]\n",
    "    \n",
    "    return beams[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findClosestTranscription(decodedTranscript, phoneticTranscription):\n",
    "    \n",
    "    dist = Levenshtein.distance(decodedTranscript, phoneticTranscription)\n",
    "\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testOperation(model, device, valLoader, Loss):\n",
    "    model.eval()\n",
    "    totalLoss = 0\n",
    "    Outputs = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets, inputLengths, targetLengths in valLoader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            inputLengths, targetLengths = inputLengths.to(device), targetLengths.to(device)\n",
    "            \n",
    "            outputs = model(inputs) \n",
    "\n",
    "            loss = Loss(outputs, targets, inputLengths, targetLengths)\n",
    "            totalLoss += loss.item()\n",
    "            Outputs.append(outputs.transpose(0, 1))\n",
    "\n",
    "    return Outputs, totalLoss / len(valLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"ortedIndices = np.argsort(valLOSS)\n",
    "\n",
    "chosenEpoch = None\n",
    "\n",
    "for idx in sortedIndices:\n",
    "    if idx > 0 and idx < len(valLOSS) - 1: \n",
    "        currentLoss = valLOSS[idx]\n",
    "        threshold = currentLoss * 1.2\n",
    "\n",
    "        if valLOSS[idx - 1] <= threshold and valLOSS[idx + 1] <= threshold:\n",
    "            chosenEpoch = idx\n",
    "            break\n",
    "\n",
    "epoch = chosenEpoch\n",
    "print(epoch)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST LOSS:  0.7542564123868942\n"
     ]
    }
   ],
   "source": [
    "modelWeight = torch.load(\"DATA/ckptsSmallVocab/ckptSmallVocabManifoldNoODE.pt\", weights_only = True)\n",
    "model.load_state_dict(modelWeight)\n",
    "output, testLoss = testOperation(model, device, testDataloader, lossFunction)\n",
    "output = torch.concatenate(output)\n",
    "\n",
    "print(\"TEST LOSS: \", testLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "decodedOut = []\n",
    "for i in range(396):\n",
    "    decodedSymbols = beamSearch(output[i].cpu().numpy(), testInputLengths[i])\n",
    "    phoneOut = []\n",
    "    for i in range(len(decodedSymbols)):\n",
    "        phoneOut.append(PHONE_DEF[decodedSymbols[i]])\n",
    "    decodedOut.append(phoneOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded phoneme sequence:  ['W', 'EH', 'N', 'Z', 'D', 'IY']\n",
      "Ground truth phoneme sequence:  ['W', 'EH', 'N', 'Z', 'D', 'IY']\n",
      "Ground truth label:  wednesday\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Visualize decoded words.\"\"\"\n",
    "\n",
    "which = 0\n",
    "print(\"Decoded phoneme sequence: \", decodedOut[which])\n",
    "print(\"Ground truth phoneme sequence: \", phonemizedWords[1600 + which])\n",
    "print(\"Ground truth label: \", allWORDS[1600 + which])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "levs = []\n",
    "phoneLENGTHS = []\n",
    "for i in range(len(decodedOut)):\n",
    "    phoneLENGTHS.append(len(phonemizedWords[1600 + i]))\n",
    "    levs.append(findClosestTranscription(decodedOut[i], phonemizedWords[1600 + i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean length of sentences:  7.825757575757576\n",
      "Mean phoneme error rate (insertion errors + deletion errors + substitution errors):  1.1893939393939394\n",
      "Percent phoneme error:  0.15198451113262343\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean length of sentences: \", np.mean(phoneLENGTHS))\n",
    "print(\"Mean phoneme error rate (insertion errors + deletion errors + substitution errors): \", np.mean(levs))\n",
    "print(\"Percent phoneme error: \", np.mean(levs)/np.mean(phoneLENGTHS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Calculate word error rate.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Small vocab word-to-phoneme dictionary.\"\"\"\n",
    "\n",
    "with open('DATA/ckptsSmallVocab/smallVocabDict.pkl', 'rb') as f:\n",
    "    smallVocabDict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findClosestTranscriptionWords(decodedTranscript, combinedDict):\n",
    "    \n",
    "    minDistance = float('inf')\n",
    "    closestKeys = []\n",
    "\n",
    "    for key, phoneticTranscription in combinedDict.items():\n",
    "        dist = distance(decodedTranscript, phoneticTranscription)\n",
    "        \n",
    "        if dist < minDistance:\n",
    "            minDistance = dist\n",
    "            closestKeys = [key]\n",
    "        elif dist == minDistance:\n",
    "            minDistance = dist\n",
    "            closestKeys.append(key)\n",
    "        \n",
    "\n",
    "    return closestKeys, minDistance\n",
    "\n",
    "def checkCorrectness(actual, predicted):\n",
    "    \n",
    "    actualWords = actual.split()\n",
    "    correctCount = 0\n",
    "    \n",
    "    for i, prediction in enumerate(predicted):\n",
    "        predicted[i] = prediction.split()\n",
    "        \n",
    "    actual = actual.split()\n",
    "    compare = len(predicted)\n",
    "\n",
    "    for i, word in enumerate(actual):\n",
    "        tally = 0\n",
    "        for j in range(len(predicted)):\n",
    "            if i < len(predicted[j]):\n",
    "                if word == predicted[j][i]:\n",
    "                    tally += 1\n",
    "        if tally == compare:\n",
    "            correctCount += 1\n",
    "            \n",
    "    return correctCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word decoding accuracy:  0.8155339805825242\n",
      " \n"
     ]
    }
   ],
   "source": [
    "finalDecode = []\n",
    "for i in range(len(decodedOut)):\n",
    "    decodedResult, ld = findClosestTranscriptionWords(decodedOut[i], smallVocabDict)\n",
    "    finalDecode.append(decodedResult)\n",
    "\n",
    "levDistance = 0\n",
    "for i in range(len(decodedOut)):\n",
    "    levDistance += distance(decodedOut[i], phonemizedWords[1600 + i])\n",
    "\n",
    "totalWords = 0\n",
    "for i in range(396):\n",
    "    w = allWORDS[1600 + i]\n",
    "    w = w.replace(\"-\", \" \").lower()\n",
    "    x = w.split(\" \")\n",
    "    totalWords += len(x)\n",
    "\n",
    "singleCorrects = 0\n",
    "singleTotal = 0\n",
    "\n",
    "for i in range(396):\n",
    "    w = allWORDS[1600 + i]\n",
    "    w = w.replace(\"-\", \" \").lower()\n",
    "    x = w.split(\" \")\n",
    "    \n",
    "    c = finalDecode[i]\n",
    "\n",
    "    if len(x) == 1:\n",
    "        singleTotal += 1\n",
    "        if len(c) == 1:\n",
    "            if x[0]  in c:\n",
    "                singleCorrects += 1\n",
    "\n",
    "notSingleCorrects = 0\n",
    "notSingleTotal = 0\n",
    "\n",
    "for i in range(396):\n",
    "    w = allWORDS[1600 + i]\n",
    "    \n",
    "    w = w.replace(\"-\", \" \").lower()\n",
    "    x = w.split(\" \")\n",
    "    \n",
    "    c = finalDecode[i]\n",
    "    if len(x) > 1:\n",
    "        notSingleTotal += len(x)\n",
    "        \n",
    "        corrects = checkCorrectness(w, c)\n",
    "        notSingleCorrects += corrects\n",
    "\n",
    "print(\"Word decoding accuracy: \", (notSingleCorrects + singleCorrects)/totalWords)\n",
    "print(\" \")\n",
    "\n",
    "LEV = []\n",
    "ACC = []\n",
    "LEV.append(levDistance)\n",
    "ACC.append((notSingleCorrects + singleCorrects)/totalWords)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emgSpeech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
