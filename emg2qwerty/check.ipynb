{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ce1a617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from omegaconf import OmegaConf\n",
    "from hydra.utils import instantiate\n",
    "\n",
    "from emg2qwerty import transforms, utils\n",
    "from hydra import initialize, compose\n",
    "from emg2qwerty.data import WindowedEMGDataset\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from emg2qwerty.transforms import Compose, ToTensor, LogSpectrogram, TemporalAlignmentJitter, IdentityTransform, RandomBandRotation, SlidingCovariance, SpecAugment, ZNormalizeTime\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import logging\n",
    "from emg2qwerty.lightning import WindowedEMGDataModule\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f4ed66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Train the emg2qwerty model. \n",
    "\n",
    "Code taken from: \n",
    "Sivakumar, Viswanath, et al. \n",
    "\"emg2qwerty: A large dataset with baselines for touch typing using surface electromyography.\" \n",
    "Advances in Neural Information Processing Systems 37 (2024): 91373-91389.\n",
    "\n",
    "https://github.com/facebookresearch/emg2qwerty\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d15ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "According to your setup, you need to change,\n",
    "\n",
    "dataset:\n",
    "  root: /mnt/dataDrive/qwertyData/data in base.yaml\n",
    "\n",
    "and \n",
    "lm_path: /mnt/dataDrive/emgFullCorpora/toUpload/emg2qwerty/models/wikitext-103-6gram-charlm.bin in ctc_beam.yaml\n",
    "\n",
    "in config files.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "All codes are same except that we use SlidingCovariance instead of log spectrogams.\n",
    "We also train for 250 epochs instead of 150 epochs since our model took longer to converge. \n",
    "\n",
    "The rest of the things are same as in https://github.com/facebookresearch/emg2qwerty.\n",
    "This is a controlled experiment to show that covariance features rae better than spectral features. \n",
    "\n",
    "We train two different variations: one where covariance matrices are approximately diagonalized, and one where they are not.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "826698d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"deocder = ctc_beam or ctc_greedy\n",
    "approxDiag = True or False\n",
    "\"\"\"\n",
    "\n",
    "user = \"user0\"\n",
    "decoder = \"ctc_greedy\" \n",
    "approxDiag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1c9e4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with initialize(config_path = \"config\", version_base = None):\n",
    "    config = compose(\n",
    "        config_name = \"base\",\n",
    "        overrides=[\n",
    "            f\"user={user}\",\n",
    "            f\"decoder={decoder}\"\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bc55f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../DATA/emg2qwerty/frechetMean/\" + user + \"Mean.pkl\", \"rb\") as f:\n",
    "    userMean = pickle.load(f)\n",
    "meanLeft = userMean[\"left\"]\n",
    "meanRight = userMean[\"right\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33070788",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvaluesL, eigenvectorsL = np.linalg.eig(meanLeft)\n",
    "\n",
    "eigenvaluesR, eigenvectorsR = np.linalg.eig(meanRight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df5b05f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvectorsLeft = torch.tensor(eigenvectorsL, dtype = torch.float32)\n",
    "eigenvectorsRight = torch.tensor(eigenvectorsR, dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ddff167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fullSessionPaths(dataset, root):\n",
    "    sessions = [s[\"session\"] for s in dataset]\n",
    "    return [Path(root) / f\"{session}.hdf5\" for session in sessions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85801c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user': 'user0', 'dataset': {'train': [{'user': 43037958, 'session': '2020-12-17-1608244656-keystrokes-dca-study@1-e041d7d9-a53b-40f3-aabc-e9714072ca46'}, {'user': 43037958, 'session': '2020-12-17-1608255062-keystrokes-dca-study@1-e041d7d9-a53b-40f3-aabc-e9714072ca46'}, {'user': 43037958, 'session': '2020-12-17-1608257601-keystrokes-dca-study@1-e041d7d9-a53b-40f3-aabc-e9714072ca46'}, {'user': 43037958, 'session': '2020-12-17-1608268481-keystrokes-dca-study@1-e041d7d9-a53b-40f3-aabc-e9714072ca46'}, {'user': 43037958, 'session': '2020-12-18-1608304463-keystrokes-dca-study@1-e041d7d9-a53b-40f3-aabc-e9714072ca46'}, {'user': 43037958, 'session': '2020-12-18-1608314177-keystrokes-dca-study@1-e041d7d9-a53b-40f3-aabc-e9714072ca46'}, {'user': 43037958, 'session': '2020-12-18-1608311446-keystrokes-dca-study@1-e041d7d9-a53b-40f3-aabc-e9714072ca46'}, {'user': 43037958, 'session': '2020-12-17-1608220409-keystrokes-dca-study@1-e041d7d9-a53b-40f3-aabc-e9714072ca46'}, {'user': 43037958, 'session': '2020-12-17-1608223018-keystrokes-dca-study@1-e041d7d9-a53b-40f3-aabc-e9714072ca46'}, {'user': 43037958, 'session': '2020-12-17-1608217769-keystrokes-dca-study@1-e041d7d9-a53b-40f3-aabc-e9714072ca46'}], 'val': [{'user': 43037958, 'session': '2020-12-17-1608249257-keystrokes-dca-study@1-e041d7d9-a53b-40f3-aabc-e9714072ca46'}, {'user': 43037958, 'session': '2020-12-18-1608306627-keystrokes-dca-study@1-e041d7d9-a53b-40f3-aabc-e9714072ca46'}], 'test': [{'user': 43037958, 'session': '2020-12-17-1608247041-keystrokes-dca-study@1-e041d7d9-a53b-40f3-aabc-e9714072ca46'}, {'user': 43037958, 'session': '2020-12-17-1608266139-keystrokes-dca-study@1-e041d7d9-a53b-40f3-aabc-e9714072ca46'}], 'root': '/mnt/dataDrive/qwertyData/data'}, 'to_tensor': {'_target_': 'emg2qwerty.transforms.ToTensor', 'fields': ['emg_left', 'emg_right']}, 'band_rotation': {'_target_': 'emg2qwerty.transforms.ForEach', 'transform': {'_target_': 'emg2qwerty.transforms.RandomBandRotation', 'offsets': [-1, 0, 1]}}, 'temporal_jitter': {'_target_': 'emg2qwerty.transforms.TemporalAlignmentJitter', 'max_offset': 120}, 'logspec': {'_target_': 'emg2qwerty.transforms.LogSpectrogram', 'n_fft': 64, 'hop_length': 16}, 'specaug': {'_target_': 'emg2qwerty.transforms.SpecAugment', 'n_time_masks': 3, 'time_mask_param': 25, 'n_freq_masks': 2, 'freq_mask_param': 4}, 'bandwise_covariance': {'_target_': 'emg2qwerty.transforms.SlidingCovariance'}, 'flatten_spd': {'_target_': 'emg2qwerty.transforms.FlattenSPDSequence'}, 'transforms': {'train': ['${to_tensor}', '${band_rotation}', '${temporal_jitter}', '${bandwise_covariance}'], 'val': ['${to_tensor}', '${bandwise_covariance}'], 'test': '${transforms.val}'}, 'module': {'_target_': 'emg2qwerty.lightning.TDSConvCTCModule', 'in_features': 528, 'mlp_features': [384], 'block_channels': [24, 24, 24, 24], 'kernel_width': 32}, 'datamodule': {'_target_': 'emg2qwerty.lightning.WindowedEMGDataModule', 'window_length': 8000, 'padding': [1800, 200]}, 'optimizer': {'_target_': 'torch.optim.Adam', 'lr': 0.001, 'weight_decay': 0.001}, 'lr_scheduler': {'scheduler': {'_target_': 'pl_bolts.optimizers.lr_scheduler.LinearWarmupCosineAnnealingLR', 'warmup_epochs': 10, 'max_epochs': '${trainer.max_epochs}', 'warmup_start_lr': 1e-08, 'eta_min': 1e-06}, 'interval': 'epoch'}, 'decoder': {'_target_': 'emg2qwerty.decoder.CTCGreedyDecoder'}, 'seed': 0, 'batch_size': 32, 'num_workers': 4, 'train': True, 'checkpoint': None, 'monitor_metric': 'val/CER', 'monitor_mode': 'min', 'trainer': {'accelerator': 'gpu', 'devices': 1, 'num_nodes': 1, 'max_epochs': 250, 'default_root_dir': '${hydra:runtime.output_dir}', 'val_check_interval': 1.0}, 'callbacks': [{'_target_': 'pytorch_lightning.callbacks.LearningRateMonitor'}, {'_target_': 'pytorch_lightning.callbacks.ModelCheckpoint', 'dirpath': '${hydra:runtime.output_dir}/checkpoints', 'monitor': '${monitor_metric}', 'mode': '${monitor_mode}', 'save_last': True, 'verbose': True}]}\n"
     ]
    }
   ],
   "source": [
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d235c1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainTransform = Compose([\n",
    "    ToTensor(fields=['emg_left', 'emg_right'], stack_dim = 1),\n",
    "    ZNormalizeTime(),\n",
    "    RandomBandRotation(),\n",
    "    TemporalAlignmentJitter(max_offset = 120, stack_dim = 1),\n",
    "    SlidingCovariance(eigenvectorsL = eigenvectorsLeft, eigenvectorsR = eigenvectorsRight, approxDiag = approxDiag)\n",
    "])\n",
    "\n",
    "valTransform = Compose([\n",
    "    ToTensor(fields=['emg_left', 'emg_right'], stack_dim = 1),\n",
    "    ZNormalizeTime(),\n",
    "    SlidingCovariance(eigenvectorsL = eigenvectorsLeft, eigenvectorsR = eigenvectorsRight, approxDiag = approxDiag)\n",
    "])\n",
    "\n",
    "testTransform = Compose([\n",
    "    ToTensor(fields=['emg_left', 'emg_right'], stack_dim = 1),\n",
    "    ZNormalizeTime(),\n",
    "    SlidingCovariance(eigenvectorsL = eigenvectorsLeft, eigenvectorsR = eigenvectorsRight, approxDiag = approxDiag)\n",
    "])\n",
    "\n",
    "trainSessions = fullSessionPaths(config.dataset.train, config.dataset.root)\n",
    "valSessions = fullSessionPaths(config.dataset.val, config.dataset.root)\n",
    "testSessions = fullSessionPaths(config.dataset.test, config.dataset.root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5017281b",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = instantiate(\n",
    "    config.datamodule,\n",
    "    batch_size = config.batch_size,\n",
    "    num_workers = config.num_workers,\n",
    "    train_sessions = trainSessions,\n",
    "    val_sessions = valSessions,\n",
    "    test_sessions = testSessions,\n",
    "    train_transform = trainTransform,\n",
    "    val_transform = valTransform,\n",
    "    test_transform = testTransform,\n",
    "    _convert_ = \"object\"\n",
    ")\n",
    "\n",
    "\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7acc045",
   "metadata": {},
   "outputs": [],
   "source": [
    "from emg2qwerty.lightning import TDSConvCTCModule\n",
    "from emg2qwerty.charset import charset\n",
    "import torch.optim as optim\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2002a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TDSConvCTCModule(\n",
    "    in_features = 16 * 16,\n",
    "    mlp_features = config.module.mlp_features,\n",
    "    block_channels = config.module.block_channels,\n",
    "    kernel_width = config.module.kernel_width,\n",
    "    optimizer = config.optimizer,\n",
    "    lr_scheduler = config.lr_scheduler,\n",
    "    decoder = config.decoder,\n",
    "    share_hand_weights = False\n",
    ")\n",
    "\n",
    "checkpointCB = ModelCheckpoint(\n",
    "    monitor = 'val/loss',\n",
    "    save_top_k = 1,\n",
    "    mode = 'min',\n",
    "    filename = 'best-model',\n",
    "    save_last = True,\n",
    "    dirpath = './checkpoints'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67a4d81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "lrMonitor = LearningRateMonitor(logging_interval = 'epoch')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator = 'gpu',\n",
    "    devices = 1,\n",
    "    max_epochs = config.trainer.max_epochs,\n",
    "    callbacks = [checkpointCB, lrMonitor],\n",
    "    default_root_dir = './outputs',\n",
    "    log_every_n_steps = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c1fec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Train the model. Skip this cell if you simpy want simply test with the given checkpoints. \"\"\"\n",
    "\n",
    "trainer.fit(model, datamodule = datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1739bbab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if approxDiag:\n",
    "    where = \"withApproxDiag\"\n",
    "else: \n",
    "    where = \"withoutApproxDiag\"\n",
    "\n",
    "checkpoint = torch.load(\"../DATA/emg2qwerty/\" + where + \"/\" + user + \".ckpt\")\n",
    "model.load_state_dict(checkpoint[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3ecd4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0:  15%|█▌        | 3/20 [00:00<00:02,  5.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/k2/miniconda3/envs/emg2qwerty/lib/python3.10/site-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at /opt/conda/conda-bld/pytorch_1712608935911/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0: 100%|██████████| 20/20 [00:01<00:00, 15.66it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     Validate metric           DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "         val/CER            20.588546752929688\n",
      "         val/DER            3.3767333030700684\n",
      "         val/IER             5.186831951141357\n",
      "         val/SER            12.024981498718262\n",
      "        val/loss            1.1117563247680664\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'val/loss': 1.1117563247680664,\n",
       "  'val/CER': 20.588546752929688,\n",
       "  'val/IER': 5.186831951141357,\n",
       "  'val/DER': 3.3767333030700684,\n",
       "  'val/SER': 12.024981498718262}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.validate(model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ad34e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 2/2 [00:01<00:00,  1.02it/s]\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test/CER            22.537473678588867\n",
      "        test/DER             1.970021367073059\n",
      "        test/IER             6.937901496887207\n",
      "        test/SER            13.629549980163574\n",
      "        test/loss           1.1046416759490967\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test/loss': 1.1046416759490967,\n",
       "  'test/CER': 22.537473678588867,\n",
       "  'test/IER': 6.937901496887207,\n",
       "  'test/DER': 1.970021367073059,\n",
       "  'test/SER': 13.629549980163574}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(model, datamodule = datamodule)         "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emg2qwerty",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
